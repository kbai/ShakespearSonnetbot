%
\subsection{Rhyme}\label{sec:rhymedict}
The naive approach to generate poems does not honor the rhyme pattern in the Shakespear's sonnets. However, it is actually not difficult to introduce rhyme in our group-based poem generating algorithms. There are two steps to generate poems with rhymes: first, build a rhyming dictionary; second, seed the end of the line with words that rhyme, and then do HMM generation in the reverse direction.

To build a rhyming dictionary, we pick out the last words of pair of rhyming lines. If these two words rhyme, we add it to the rhyming dictionary. For example, ``increase" and ``decease" rhyme with the same phonetic ``IY-S" (\texttt{cmudict} phonetic form), and thus we generate an phonetic item ``IY-S" in the rhyming dictionary with two words ``increase" and ``decease". In Sonnet 11, we find another pair ``increase" and ``cease" also rhyme with ``IY-S". Then, we add ``cease" into the item ``IY-S". Sometimes, the last words of pair of rhyming lines do not rhyme, like ``die" and ``memory". In this case, we only check these two words separately whether they can be added into some existing phonetic item. For example, ``die" can be added into the phonetic item ``AY" and ``memory" can be added into the phonetic item ``IY". After traversing all the rhyming lines twice, we build a rhyming dictionary for each corpus. 

We combine the \textit{NLTK} package and the RhymeBrain website~\url{http://rhymebrain.com/en} to identify whether two words rhyme or not and the phonetic they rhyme. For the word which exists in \texttt{cmudict} (in \textit{NLTK}), we use \textit{NLTK} to get its phonetics. For example, 
\begin{lstlisting}
>>> phondict = nltk.corpus.cmudict.dict()
>>> phondict['increase']
[[u'IH0', u'N', u'K', u'R', u'IY1', u'S'], [u'IH1', u'N', u'K', u'R', u'IY2', u'S']]
\end{lstlisting}
If either of the pronunciation rhymes with other word, like ``cease", we think that these two words rhyme. For the word which does not exists in \texttt{cmudict}, our script \textit{automatically} picks an auxiliary word which rhyme with this word from the RhymeBrain website~\url{http://rhymebrain.com/en}, and use the phonetics of the auxiliary word to analyze the rhyme. For example, ``fulfil" does not exists in \texttt{cmudict}. Our script will go to the RhymeBrain website and pick the word ``foothill". Then we use 
\begin{lstlisting}
>>> phondict['foothill']
[[u'F', u'UH1', u'T', u'HH', u'IH2', u'L']]
\end{lstlisting}
to analyze whether ``fulfil" and ``will" rhyme, and the answer is yes!

In this case, we train the HMM or 2rd-order Markov model in the reverse direction. To do this, we only need to reverse every line in the input corpus. To generate a poem, we first seed the end of the line with words that rhyme, and then generate lines with the reverse-direction-trained model. The following are several rhyming lines generated by trained HMM for \texttt{groupG} with number of hidden state 80.
\begin{lstlisting}
 as  with  proves  replete  in  thee  writ 
 even  see  shall  accessary  used  must  find  and  herself  enfeebled  mine  it 
 she  this  and  thee  praise 
 then  love  away  night  seat  is  one  days 
 this  even  had  in  lived  their  young  part 
 yet  subjects  knife  what  right  winter  thee  heart 
 and  thou  feelst  find  bear  wretchcd  your  store  line 
 that  other  not  may  it  of  shows  this  mine  in  writ  mine 
 pity  mayst  be  you  made  to  praise  best 
 the  thee  be  him  and  length  time  thou  am  still  breast 
\end{lstlisting}
We can see that the lines alway rhyme, but the number of syllables varies a lot.

\subsection{Controlling the total number of syllables in a line}
There are several ways to control the total number of syllables in each line and ideally to make it exactly 10. We take a very simple approach to do this: repeatedly generating lines until the total number of syllables is 10. Sometimes, it takes a long time to get a line with exactly 10 syllables. Therefore, we randomly generate at most 50 lines, and keep the line whose total number of syllables is closest to 10.

To count the total number of syllables in each line, we need to count the number of syllables in each word. We combine the \textit{NLTK} package, the \textit{PyHyphen} package and our own-written function \texttt{count\_syllables()} to count the number of syllables in each word as accurate as possible. If a word is in \texttt{cmudict}, the \textit{NLTK} gives us the right answer. For examples, ``increase" has 2 syllables according to \texttt{cmudict}. If a word is not in \texttt{cmudict}, we use \textit{PyHyphen} to count the syllables. For example,
\begin{lstlisting}
In[4]: from hyphen import Hyphenator
In[5]:  h_en = Hyphenator('en_US')
In[6]: len(h_en.syllables(unicode('fulfil')))
Out[6]: 2
In[7]: len(h_en.syllables(unicode('air')))
Out[7]: 0
\end{lstlisting}
We can see that the \textit{PyHyphen} package is not so accurate to identify the number of syllables in a word. Therefore, we also write our own function \texttt{count\_syllables()} (see file \texttt{countvowel.py}) to correct possible mistakes made by the \textit{PyHyphen} package.

With this approach to control the total number of syllables in a line, we get rhyming lines all of which have total number of syllables nearly 10. The following are several rhyming lines generated by trained 2rd-order Markov model for \texttt{groupG}.
\begin{lstlisting}
 which  die  for  goodness  who  have  lived  for  crime 
 but  were  some  child  of  yours  alive  that  time 
 to  give  back  again  and  straight  grow  sad 
 this  told  joy  but  then  no  longer  glad 
 lo  thus  by  day  my  limbs  by  night  my  mind 
 for  thee  and  for  my  name  thy  love  and  am  blind 
 think  all  but  one  and  me  most  wretchcd  make 
 till  then  not  show  my  head  where  thou  mayst  take 
 so  till  the  judgment  that  your  self  arise 
 so  long  lives  this  and  dwell  in  lovers  eyes 
\end{lstlisting}
We can see that the lines alway rhyme, and the total number of syllables in each line is nearly 10.


\subsection{Incorporating additional texts}
Our framework enables us to train our models with additional texts. We include all 139 of Spenser?s sonnets in our training datasets. With the same process, i.e., pre-processing, rhyme dictionary learning, model training (for both HMM and 2rd-order Markov model), we can easy get models which have a larger dictionary. The training time nearly get doubled because we have nearly double sized training data. The following is one poem from our trained 2rd-order Markov model, with rhyming and controlling-the-total-number-of-syllables.



